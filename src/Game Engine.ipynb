{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe713e1-f1e4-44f3-b6ea-9cc7a30187fb",
   "metadata": {},
   "source": [
    "# Arize Game Engine Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d9857-e797-4f35-8b68-8ae395fb0a23",
   "metadata": {},
   "source": [
    "### Load Passwords and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0aa922e-f50b-49c9-8673-ec9c83fac07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "for key in [\"OPENAI_API_KEY\"]:\n",
    "    if not os.environ.get(key):\n",
    "        print(f\"Please enter key: '{key}'\")\n",
    "        os.environ[key] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfd96b3-7be5-41a1-a680-de607516d014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active session to close\n",
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import phoenix as px\n",
    "\n",
    "nest_asyncio.apply()\n",
    "px.close_app()\n",
    "px.launch_app()\n",
    "\n",
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2681c5d5-b074-4795-9121-2014583d5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1df66-a60c-4db8-ba79-2c7903d64124",
   "metadata": {},
   "source": [
    "### Build the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3611b84-c601-48c8-8244-81646251b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt = \"\"\"\n",
    "### General Instructions\n",
    "1. You are acting as the game engine for a text based adventure game. You are the equivalent of a D&D dungeon master.\n",
    "2. The human controlling the player character will issue instructions to move their character around. \n",
    "3. You will respond in a way consistent with their previous actions and with the game state. Never acknowledge that a game is being played.\n",
    "\n",
    "### Specific Instructions\n",
    "You must:\n",
    "1. Write in the second person and use the word \"you\" to describe the character\n",
    "2. Maintain inventory management\n",
    "3. Treat any text wrapped in square brackets as a hint as to where the player is. For example \"[Center Room] Look around\" should result in you describing the center room.\n",
    "\n",
    "### Inventory Rules\n",
    "1. When a player picks up an object, it is added to their inventory. It remains in their inventory until it is used. \n",
    "2. Inventory is empty to start \n",
    "3. Inventory has a capacity of 10 items\n",
    "\n",
    "### Cutscene Interactions\n",
    "1. When the player touches the glowing orb in the north room a cutscene should be triggered\n",
    "\n",
    "### Description Rules\n",
    "All descriptions come from room documents. You cannot make up any additional details.\n",
    "\n",
    "{context}\n",
    "\n",
    "User Interaction: {interaction}\n",
    "\n",
    "### Response:\n",
    "\n",
    "One to three sentence response to the user interaction.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e566874-0ff2-4264-831c-9984d90734ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Inventory(BaseModel):\n",
    "    items: List[str] = Field(..., description=\"items in the player's inventory\")\n",
    "    max_capacity: int = Field(10, description=\"the maximum number of items the player can hold\")\n",
    "\n",
    "class GameState(BaseModel):\n",
    "    inventory: Inventory = Field(..., description=\"the player's inventory\")\n",
    "    response: str = Field(..., description=\"your response to the player based on their latest interaction as described in the prompt. For example, the interaction 'what is in this room' should result in a description of the current room.\")\n",
    "    trigger_orb_cutscene: bool = Field(..., description=\"whether an orb cutscene should occur as described in the prompt\")\n",
    "    room: str = Field(\"Center Room\", description=\"the room in which the character is currently located as shown by the reference document. For example, if the reference document is titled 'Center Room' this should be filled with 'Center Room'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2c779db-80f3-420d-864b-0f0aa2d8d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_retriever():\n",
    "    loader = DirectoryLoader('game_data', glob=\"room_*\", loader_cls=TextLoader)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "    return retriever\n",
    "\n",
    "def get_llm_chain():\n",
    "    prompt = ChatPromptTemplate.from_template(text_prompt)\n",
    "    \n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0).bind_tools([GameState])\n",
    "\n",
    "    retriever = load_retriever()\n",
    "    llm_chain = (\n",
    "        {\"context\": retriever | format_docs, \"interaction\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | JsonOutputToolsParser()\n",
    "    )\n",
    "    return llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "102d7d8c-410a-43e8-bbed-b3108de94314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  Where am I?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in the Center Room, a dimly lit space with a skylight high above. There's a desk, a cupboard, and an old lamp here, along with a box of matchsticks on the desk and a rusty dagger and quart of oil in the cupboard.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  I pick up the box of match sticks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You pick up the box of match sticks from the desk. It feels light in your hand, and you can hear the two matches rattling inside.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  Are there any rooms I can enter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry - I don't understand that command\n",
      "You pick up the box of match sticks from the desk. It feels light in your hand, and you can hear the two matches rattling inside.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  Find a door\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You pull on each of the candlesticks on the walls. Each one reveals a door leading in the direction the wall faces.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  Go north\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You move north, entering a room that is completely empty except for an enormous and menacingly glowing orb.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  Touch the orb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As you reach out and touch the orb, it pulses with a strange energy. Suddenly, the room around you seems to fade away.\n",
      "CUT SCENE TRIGGERED!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  quit\n"
     ]
    }
   ],
   "source": [
    "class GameEngine:\n",
    "    def __init__(self, llm_chain):\n",
    "        self.llm_chain = llm_chain\n",
    "        self.state = {}\n",
    "\n",
    "    def input(self, text):\n",
    "        new_state = self.llm_chain.invoke(text)\n",
    "        if len(new_state) == 0:\n",
    "            print(\"I'm sorry - I don't understand that command\")\n",
    "        else:\n",
    "            self.state = new_state[0]['args']\n",
    "\n",
    "    def react(self):\n",
    "        if self.state.get('response'):\n",
    "            print(self.state['response'])\n",
    "\n",
    "        if self.state.get('trigger_orb_cutscene'):\n",
    "            print(\"CUT SCENE TRIGGERED!\")\n",
    "\n",
    "def play_game():\n",
    "    game = GameEngine(get_llm_chain())\n",
    "\n",
    "    while True:\n",
    "        text = input(\">>> \")\n",
    "        if text == \"quit\":\n",
    "            break\n",
    "        game.input(text)\n",
    "        game.react()\n",
    "\n",
    "play_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87de83-0ecc-4002-be22-aebb42c471ad",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We care about quite a few different metrics for this text adventure game - tendency to hallucinate, document relevance, state tracking and whether key events get triggered at the right time.\n",
    "\n",
    "Let's focus on document relevance and tendency to hallucinate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b26af-9248-40b1-b4cf-4bccbd841f6b",
   "metadata": {},
   "source": [
    "#### Hallucination Evaluation Playground\n",
    "https://docs.arize.com/phoenix/evaluation/running-pre-tested-evals/hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26513e50-9a44-4881-9076-f60d2ae84563",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdocs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a639b96f-a003-4f70-b91f-097dcc4fc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from phoenix.experimental.evals import (\n",
    "    HALLUCINATION_PROMPT_RAILS_MAP,\n",
    "    HALLUCINATION_PROMPT_TEMPLATE,\n",
    "    OpenAIModel,\n",
    "    download_benchmark_dataset,\n",
    "    llm_classify,\n",
    ")\n",
    "from pycm import ConfusionMatrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "llm_chain = get_llm_chain()\n",
    "loader = DirectoryLoader('game_data', glob=\"room_*\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "# Let's test some basic center room hallucinations\n",
    "hallucination_test_data = []\n",
    "for query in [\n",
    "    \"I pick up an orange\",\n",
    "    \"I take a candle from a candlestick\",\n",
    "    \"I look around and see President Barack Obama\"\n",
    "]:\n",
    "    game_state = llm_chain.invoke(query)\n",
    "    hallucination_test_data.append({\n",
    "        \"query\": query,\n",
    "        \"reference\": docs[0].page_content,\n",
    "        \"response\": game_state[0][\"args\"].get('response') if game_state else ''\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bf43feb-40e4-4069-baf4-26a34bb26f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error while constructing the prompts from the template and dataframe. The template variable 'input' is not found as a column in the dataframe.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/phoenix/experimental/evals/templates/template.py:179\u001b[0m, in \u001b[0;36mmap_template\u001b[0;34m(dataframe, template, options)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompts\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m     results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m         \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/phoenix/experimental/evals/templates/template.py:181\u001b[0m, in \u001b[0;36mmap_template.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m--> 181\u001b[0m             variable_values\u001b[38;5;241m=\u001b[39m\u001b[43m{\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[1;32m    182\u001b[0m             options\u001b[38;5;241m=\u001b[39mprompt_options,\n\u001b[1;32m    183\u001b[0m         ),\n\u001b[1;32m    184\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompts\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/phoenix/experimental/evals/templates/template.py:181\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m--> 181\u001b[0m             variable_values\u001b[38;5;241m=\u001b[39m{var_name: \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m template\u001b[38;5;241m.\u001b[39mvariables},\n\u001b[1;32m    182\u001b[0m             options\u001b[38;5;241m=\u001b[39mprompt_options,\n\u001b[1;32m    183\u001b[0m         ),\n\u001b[1;32m    184\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompts\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m OpenAIModel(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-turbo-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m rails \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(HALLUCINATION_PROMPT_RAILS_MAP\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m----> 9\u001b[0m hallucination_classifications \u001b[38;5;241m=\u001b[39m \u001b[43mllm_classify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHALLUCINATION_PROMPT_TEMPLATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrails\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m hallucination_classifications\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/phoenix/experimental/evals/functions/classify.py:153\u001b[0m, in \u001b[0;36mllm_classify\u001b[0;34m(dataframe, model, template, rails, system_instruction, verbose, use_function_calling_if_available, provide_explanation, include_prompt, include_response, run_sync, concurrency)\u001b[0m\n\u001b[1;32m    150\u001b[0m eval_template \u001b[38;5;241m=\u001b[39m normalize_classification_template(rails\u001b[38;5;241m=\u001b[39mrails, template\u001b[38;5;241m=\u001b[39mtemplate)\n\u001b[1;32m    152\u001b[0m prompt_options \u001b[38;5;241m=\u001b[39m PromptOptions(provide_explanation\u001b[38;5;241m=\u001b[39mprovide_explanation)\n\u001b[0;32m--> 153\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[43mmap_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m labels: List[Optional[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataframe)\n\u001b[1;32m    156\u001b[0m explanations: List[Optional[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataframe)\n",
      "File \u001b[0;32m~/arize_project/.venv/lib/python3.11/site-packages/phoenix/experimental/evals/templates/template.py:188\u001b[0m, in \u001b[0;36mmap_template\u001b[0;34m(dataframe, template, options)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompts\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while constructing the prompts from the template and dataframe. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe template variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found as a column in the dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while constructing the prompts from the template and dataframe variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error while constructing the prompts from the template and dataframe. The template variable 'input' is not found as a column in the dataframe."
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(hallucination_test_data)\n",
    "\n",
    "model = OpenAIModel(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = list(HALLUCINATION_PROMPT_RAILS_MAP.values())\n",
    "hallucination_classifications = llm_classify(\n",
    "    dataframe=test_df, template=HALLUCINATION_PROMPT_TEMPLATE, model=model, rails=rails\n",
    ")\n",
    "\n",
    "hallucination_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a303e7a-7e02-41fc-a391-77f6bbea1b9d",
   "metadata": {},
   "source": [
    "#### Relevance Evaluation Playground\n",
    "Phoenix’s built-in RelevanceEvaluator doesn’t quite help us here. The default prompt doesn’t take into account the fact that we are using document retrieval in a pretty unorthodox manner and marks documents as “unrelated” even when they are related. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ce391-f994-44a3-a2c1-78cd64d8caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.experimental.evals import RelevanceEvaluator\n",
    "from phoenix.experimental.evals import run_evals\n",
    "from phoenix.session.evaluation import get_retrieved_documents\n",
    "\n",
    "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
    "\n",
    "eval_model = OpenAIModel(model=\"gpt-4-turbo-preview\", temperature=0.0)\n",
    "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
    "relevance_eval_df = run_evals(\n",
    "    dataframe=retrieved_documents_df.tail(5),\n",
    "    evaluators=[relevance_evaluator],\n",
    "    provide_explanation=True,\n",
    ")[0]\n",
    "\n",
    "relevance_eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
